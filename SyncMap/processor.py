# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_GraphProcessor.ipynb.

# %% auto 0
__all__ = ['GraphProcessor', 'WorkingMemProcessor', 'data_preprocessing', 'prepare_data', 'Readout']

# %% ../nbs/01_GraphProcessor.ipynb 4
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import warnings
from collections import deque
from tqdm import tqdm
import time
from fastcore.utils import *  # for example: patch

import seaborn as sns
sns.set_theme()

# import dbscan
from sklearn.cluster import DBSCAN
from sklearn.metrics import normalized_mutual_info_score
from scipy.cluster.hierarchy import dendrogram, linkage, maxdists
from sklearn.cluster import AgglomerativeClustering
# from SyncMap_Draft.FasterSyncMap import data_preprocessing
import torch

# %% ../nbs/01_GraphProcessor.ipynb 5
class GraphProcessor:
    def __init__(self, file_path=None):
        self.file_path = file_path
        self.G = None
        self.labels = None
        self.labels_numpy = None
        self.A = None

        # # initialize the graph
        # self.read_graph_from_dot()

    def read_graph_from_dot(self, file_path=None, show_info=True):
        if file_path is None:
            file_path = self.file_path
        if file_path is None:
            raise ValueError("File path not provided.")

        # Read graph from .dot file
        self.G = nx.DiGraph(nx.nx_agraph.read_dot(file_path))  # MultiDiGraph -> DiGraph
        self.labels = {node: self.G.nodes[node]['label'] for node in self.G.nodes}
        # convert labels to numpy int
        self.labels_numpy = np.array([int(self.labels[node]) for node in self.G.nodes])

        # get connection matrix
        num_nodes = len(self.G.nodes)
        nodes = list(self.G.nodes)
        self.A = np.zeros((num_nodes, num_nodes))

        for edge in self.G.edges:
            source = nodes.index(edge[0])
            target = nodes.index(edge[1])
            self.A[source][target] = 1

        if show_info:
            print("Graph loaded from file:", file_path)
            print("Number of nodes:", num_nodes)
            print("Number of edges:", len(self.G.edges))

# %% ../nbs/01_GraphProcessor.ipynb 11
# get the ground truth labels
@patch
def get_groundtruth_labels(self:GraphProcessor, dtype='numpy'):
    # Get groundtruth labels from node attributes
    if self.G is not None:
        if dtype == 'dict':
            return self.labels
        elif dtype == 'numpy':
            return self.labels_numpy
    else:
        print("Graph not yet loaded. Call read_graph() first.")
        return None


# %% ../nbs/01_GraphProcessor.ipynb 13
# # visualize the graph
# @patch
# def visualize_graph(self:GraphProcessor, group_labels = None, graph_layout=0):
#     # Visualize the graph

#     if self.G is not None:
#         layout_list = [nx.spring_layout, nx.circular_layout, nx.spectral_layout, nx.shell_layout, nx.kamada_kawai_layout]
#         pos = layout_list[graph_layout](self.G)

#         if group_labels is None:
#             node_color = 'skyblue'
#         # elif len(np.unique(group_labels)) <= 10:
#         #     colorbar = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'black', 'pink', 'brown', 'gray']
#         #     node_color = [colorbar[idx] for idx in (group_labels - group_labels.min())]
#         else:
#             colorbar = sns.color_palette("hls", len(np.unique(group_labels)))
#             node_color = [colorbar[idx] for idx in (group_labels - group_labels.min())]
            
#         nx.draw_networkx_nodes(self.G, pos, node_size=300, node_color=node_color, alpha=0.7)
#         nx.draw_networkx_edges(self.G, pos, arrowstyle='-|>', arrowsize=10, edge_color='gray', alpha=0.5)
#         nx.draw_networkx_labels(self.G, pos, font_size=10, font_color='black')

#         # Add edge labels to display probabilities
#         edge_labels = nx.get_edge_attributes(self.G, 'weight')
#         edge_labels = {k: f"{v:.2f}" for k, v in edge_labels.items()}  # Format weights to 2 decimal places
#         nx.draw_networkx_edge_labels(self.G, pos, edge_labels=edge_labels, font_size=10, font_color='red')
#     else:
#         print("Graph not yet loaded. Call read_graph() first.")

@patch
def visualize_graph(self:GraphProcessor, group_labels=None, graph_layout=0, with_probs = False, node_size=300, edge_width=1, arrow_size=10, font_size=10, figsize=(10, 10)):
    # Visualize the graph
    if self.G is not None:
        layout_list = [nx.spring_layout, nx.circular_layout, nx.spectral_layout, nx.shell_layout, nx.kamada_kawai_layout]
        pos = layout_list[graph_layout](self.G)

        if group_labels is None:
            node_color = 'skyblue'
        else:
            colorbar = sns.color_palette("hls", len(np.unique(group_labels)))
            node_color = [colorbar[idx] for idx in (group_labels - group_labels.min())]
        fig, ax = plt.subplots(figsize=figsize)
        nx.draw_networkx_nodes(self.G, pos, node_size=node_size, node_color=node_color, alpha=0.7, ax=ax)
        nx.draw_networkx_edges(self.G, pos, arrowstyle='-|>', arrowsize=arrow_size, edge_color='gray', alpha=0.5, width=edge_width, ax=ax)
        nx.draw_networkx_labels(self.G, pos, font_size=font_size, font_color='black', ax=ax)

        # Add edge labels to display probabilities
        if with_probs:
            edge_labels = nx.get_edge_attributes(self.G, 'weight')
            edge_labels = {k: f"{v:.2f}" for k, v in edge_labels.items()}  # Format weights to 2 decimal places
            nx.draw_networkx_edge_labels(self.G, pos, edge_labels=edge_labels, font_size=10, font_color='red', bbox=dict(facecolor='none', edgecolor='none'))

        # # Draw self-loops separately to adjust their positions
        # loop_edges = [(n, n) for n in self.G.nodes() if self.G.has_edge(n, n)]
        # loop_pos = {node: (coord[0], coord[1] - 0.1) for node, coord in pos.items()}  # Offset loop positions slightly

        # for edge in loop_edges:
        #     label = edge_labels.get(edge, "")
        #     if label:
        #         x, y = pos[edge[0]]
        #         plt.text(x, y, label, color='red', fontsize=10, ha='center', va='center', bbox=dict(facecolor='white', edgecolor='none', alpha=0.6))

        # plt.show()
    else:
        print("Graph not yet loaded. Call read_graph() first.")
    return fig, ax

# %% ../nbs/01_GraphProcessor.ipynb 15
# get the connection matrix A
@patch
def get_connection_matrix(self:GraphProcessor):
    # Generate connection matrix A
    if self.A is not None:
        return self.A
    else:
        print("Graph not yet loaded. Call read_graph() first.")
        return None

# %% ../nbs/01_GraphProcessor.ipynb 17
# Set graph from adjacency matrix
@patch
def set_graph_from_adjacency_matrix(self:GraphProcessor, A):
    # Set graph from adjacency matrix
    self.A = A
    num_states = self.A.shape[0]
    self.G = nx.DiGraph()
    for i in range(num_states):
        self.G.add_node(i, label=i)

    # Add edges with weights
    for i in range(num_states):
        for j in range(num_states):
            if A[i, j] > 0:  # Only add edges with non-zero transition probabilities
                self.G.add_edge(i, j, weight=A[i, j])

    # self.G = nx.DiGraph(A)
    self.labels = {node: i for i, node in enumerate(self.G.nodes)}
    self.labels_numpy = np.array([int(self.labels[node]) for node in self.G.nodes])

# %% ../nbs/01_GraphProcessor.ipynb 20
# ccreate a random walk on the graph for generating trajectories(Syncmap data)
@patch
def random_walk_on_graph(self:GraphProcessor, connection_matrix=None, L=3000, reset_time=None):
    if connection_matrix is None:
        connection_matrix = self.A

    num_nodes = connection_matrix.shape[0]

    # Find nodes with no outgoing connections
    no_outgoing = np.where(np.sum(connection_matrix, axis=1) == 0)[0]
    if len(no_outgoing) != 0:
        warnings.warn("Some nodes have no outgoing connections.")

    starting_node = np.random.choice(num_nodes)

    while starting_node in no_outgoing:
        warnings.warn("Starting node has no outgoing connections. Choosing another node.")
        starting_node = np.random.choice(num_nodes)

    trajectory = []
    one_hot_vectors = []

    current_node = starting_node
    steps_since_reset = 0

    print("Random walk starting node:", current_node)

    for _ in tqdm(range(L)):
        # Record current node index
        trajectory.append(current_node)

        # Generate one-hot vector for current node
        one_hot = np.zeros(num_nodes, dtype=np.bool_)
        one_hot[current_node] = True
        one_hot_vectors.append(one_hot)

        # Choose next node based on outgoing connections
        if np.sum(connection_matrix[current_node]) == 0 or (
                reset_time is not None and steps_since_reset == reset_time):
            current_node = np.random.choice(num_nodes)
            warnings.warn("No outgoing connections from current node. Choosing another node.")
            steps_since_reset = 0
        else:
            prob = connection_matrix[current_node] / np.sum(connection_matrix[current_node])
            current_node = np.random.choice(num_nodes, p=prob)
            steps_since_reset += 1

    return np.array(trajectory), np.array(one_hot_vectors)


# %% ../nbs/01_GraphProcessor.ipynb 25
@patch
def read_graph_from_gml(self: GraphProcessor, file_path:str=None, show_info:bool=True):
    '''
    agrs:
    file_path: str, path to the gml file
    show_info: bool, whether to print the graph information
    '''
    if isinstance(file_path, str):
        file_path = Path(file_path)
    assert file_path.exists(), "File does not exist."

    self.G = nx.DiGraph(nx.read_gml(file_path))
    self.labels = {node: self.G.nodes[node]['true_label'] for node in self.G.nodes}
    self.labels_numpy = np.array([int(self.labels[node]) for node in self.G.nodes])
    self.A = np.zeros((len(self.G.nodes), len(self.G.nodes)))
    for edge in self.G.edges:
        source = list(self.G.nodes).index(edge[0])
        target = list(self.G.nodes).index(edge[1])
        self.A[source][target] = 1
    if show_info:
        print("Graph loaded from file:", file_path)
        print("Number of nodes:", len(self.G.nodes))
        print("Number of edges:", len(self.G.edges))

# %% ../nbs/01_GraphProcessor.ipynb 29
class WorkingMemProcessor:
    def __init__(self, state_memory, input_size=None, time_delay=0):
        self.state_memory = state_memory
        self.input_size = input_size
        self.time_delay = time_delay

        self.working_memory = deque(maxlen=self.state_memory)

    def set_input_size(self, input_size):
        self.input_size = input_size

    def set_time_delay(self, time_delay):
        self.time_delay = time_delay

    def seq_gen_naive(self, input_seq, verbose = False):
        # input_seq is shaped as (seq_len, input_size)
        if input_seq.shape[1] != self.input_size:
            # update input_size
            self.set_input_size(input_seq.shape[1])
            if verbose:
                print("Input size updated to {}.".format(self.input_size))
            # warnings.warn("Input size updated to {}.".format(self.input_size))
                print("generate sequence...")
        # print("generate sequence...")
        time.sleep(0.1)
        output_seq = []
        for i_state in tqdm(range(len(input_seq))):
            state = input_seq[i_state]
            self.working_memory.append(state)
            # convert to numpy
            current_working_mem = np.asarray(self.working_memory)
            current_working_mem = np.sum(current_working_mem, axis=0).astype(np.bool_)

            # append to output_seq
            output_seq.append(current_working_mem)

        return np.asarray(output_seq)
    
    def __repr__(self):
        return f"Working Memory Processor: state_memory={self.state_memory}, input_size={self.input_size}, time_delay={self.time_delay}"

# %% ../nbs/01_GraphProcessor.ipynb 35
def data_preprocessing(data):
    '''
    data: np.array, shape = (N, D), N is the number of samples, D is the number of variables
    '''
    data = data > 0.1
    mask = []
    for idx, item in enumerate(data):
        if item.sum() > 1:
            mask.append(idx)
    return data[mask]


def prepare_data(file_path, max_seq_length = 200_000, 
                state_memory = 30,  use_cuda = True):
    preprocessor = GraphProcessor()
    if str(file_path).endswith('.dot'):
        preprocessor.read_graph_from_dot(file_path=file_path)
    elif str(file_path).endswith('.gml'):
        preprocessor.read_graph_from_gml(file_path=file_path)
    groundtruth_labels = preprocessor.get_groundtruth_labels()
    connection_matrix = preprocessor.get_connection_matrix()
    num_of_nodes = connection_matrix.shape[0]


    # initialize sequence generator and set state_memory
    if state_memory == 'dynamic':
        print('use dynamic state memory')
        seq_generator = WorkingMemProcessor(state_memory=int(np.clip(0.1 * num_of_nodes, 2, 30)))
    else:
        seq_generator = WorkingMemProcessor(state_memory=state_memory)

    print(f'the state memory is {seq_generator.state_memory}')
    # generate random walk on graph
    input_seq_trajectory, input_seq_onehot = preprocessor.random_walk_on_graph(L=max_seq_length, reset_time=None)

    
    input_seq = seq_generator.seq_gen_naive(input_seq=input_seq_onehot)
    
    if state_memory != 1:
        input_seq = data_preprocessing(input_seq)  # 去掉掉全0的行
    elif state_memory == 1:
        input_seq = input_seq_onehot

    if use_cuda:
        input_seq = torch.tensor(input_seq, dtype = torch.bool, device='cuda')
    print(input_seq.shape)
    return preprocessor, groundtruth_labels, num_of_nodes, input_seq

# %% ../nbs/01_GraphProcessor.ipynb 39
class Readout:
    def __init__(self, input_map=None, input_matrix=None, ground_truth=None):
        self.input_map = input_map
        self.input_matrix = input_matrix
        self.ground_truth = ground_truth
        self.predicted_labels = None
        self.NMI = None

    def cal_NMI(self, print_result=True):
        if self.predicted_labels is None:
            print("No predicted labels found. Run dbscan_() first.")
            return None
        # Calculate NMI
        self.NMI = normalized_mutual_info_score(self.ground_truth, self.predicted_labels)
        if print_result:
            print("NMI: ", self.NMI)
        return self.NMI

    def dbscan_(self, map=None, eps=0.1, min_samples=2, print_result=True):
        if map is None:
            map = self.input_map
        # DBSCAN clustering
        clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(map)
        self.predicted_labels = clustering.labels_
        if print_result:
            print("DBSCAN clustering done. Data updated.")
            print("Predicted labels: ", self.predicted_labels)
            print("Ground truth: ", self.ground_truth)
        return self.predicted_labels


    def hierarchical_organize(self, map=None, hierarchy=None, method='ward', print_result=True):
        if map is None:
            map_ = self.input_map
        else:
            map_ = map
        input_size = map_.shape[0]
        # method = "single"
        Z = linkage(map_, method)
        # fig = plt.figure(dpi=150)
        # label_list = [i for i in range(1, self.input_size+1)]
        # dendrogram(Z, color_threshold=0, above_threshold_color='k', labels=label_list)
        # dendrogram(Z, labels=label_list)

        Z_maxdists = maxdists(Z)
        d_diff_list = []
        for d in range(len(Z_maxdists) - 1):
            d_diff = Z_maxdists[d + 1] - Z_maxdists[d]
            d_diff_list.append(d_diff)

        d_diff_index = np.argsort(d_diff_list)[::-1]

        max_diff = d_diff_index[0]
        tmp_d_diff_index = [max_diff]
        for d in d_diff_index[1:]:
            if max_diff > d:
                max_diff = d
                tmp_d_diff_index.append(d)
        d_diff_index = tmp_d_diff_index

        total_hierarchy = len(d_diff_index)
        if hierarchy is not None:
            total_hierarchy = hierarchy

        labels = np.empty((total_hierarchy, input_size), dtype=int)
        for h in range(total_hierarchy):
            label = [-1 for _ in range(input_size)]
            if h < len(d_diff_index):
                n_cluster = input_size - d_diff_index[h] - 1
                label = AgglomerativeClustering(n_clusters=n_cluster, linkage=method).fit_predict(map_)
            labels[h, :] = label

        # self.labels = np.flip(labels, axis=0)
        self.labels = labels
        self.Z_linkage = Z
        print("Hierarchical clustering done. Data updated.")
        if print_result:
            print("Ground truth: ", self.ground_truth)
            print("Labels: ", self.labels)

        return self.labels

    def plot_dendrogram(self, Z=None, isPlotLabel=False, labels=None):
        if Z is None:
            Z = self.Z_linkage
            if Z is None:
                Z = linkage(self.input_map, 'ward')
        if labels is None:
            labels = self.labels

        fig = plt.figure(dpi=150)
        label_list = [i for i in range(1, labels.shape[1] + 1)]
        if isPlotLabel:
            label_list = labels[0, :]
            dendrogram(Z, color_threshold=0, above_threshold_color='k', labels=np.array(label_list))
        else:
            dendrogram(Z)
        plt.show()
        return None
